{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of gaze data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['office_sample']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from alabeye.etdata import ETdata\n",
    "\n",
    "# Main directory for experiment data.\n",
    "expdata_dir = os.path.abspath('./sample_input')\n",
    "\n",
    "# HDF file of gaze data (see ../preprocess_rawdata about how to prepare this file)\n",
    "hdf_filename = 'office_sample_etdata_compressed.hdf5'\n",
    "\n",
    "hdf_file = os.path.join(expdata_dir, hdf_filename)\n",
    "\n",
    "# 'ETdata' class from the 'alabeye.etdata' module handles most of the interface with the data\n",
    "# an initial look into the hdf file to learn available data in the hdf file \n",
    "print(ETdata(data_file=hdf_file).available_tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for a specific task:\n",
    "task2load = 'office_sample'\n",
    "\n",
    "# the video file name associated with this particular experiment task\n",
    "stimname_map = {'office_sample':'office_sample_vid.mp4'}\n",
    "\n",
    "# in addition we add some optional info about the participants/subjects\n",
    "subj_info_file = os.path.join(expdata_dir, 'participant_info.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file 'participant_info.csv' is a file that includes, at a minimum, two columns of information. The first column contains subjectIDs that are used to save eye-tracking data in the HDF file, while the second column contains information about the group to which each subject belongs, such as \n",
    "'ASD' or 'TD'. If this file is not provided, then subjectIDs will be read from the HDF file directly, and all subjects will be assumed to be part of the same group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID Group\n",
      "0    A00067   ASD\n",
      "1    A00071   ASD\n",
      "2    A00082   ASD\n",
      "3    A00083   ASD\n",
      "4    A00093   ASD\n",
      "..      ...   ...\n",
      "148  RA0999    TD\n",
      "149  RA1001    TD\n",
      "150  RA1003    TD\n",
      "151  RA1004    TD\n",
      "152  RA1005    TD\n",
      "\n",
      "[153 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# load the file just to its content, we don't need this step normally.\n",
    "subj_df = pd.read_csv(subj_info_file)\n",
    "print(subj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the 'ETdata' class for loading varios information about the experiment\n",
    "sample_etdata = ETdata(taskname=task2load, data_file=hdf_file, \n",
    "                       subj_info_file=subj_info_file,\n",
    "                       use_subj_info=True, # use the group info for the subjects \n",
    "                       stim_dir=expdata_dir, # directory where the video stimulus is\n",
    "                       stimname_map=stimname_map\n",
    "                       )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at various attributes that ETdata class have\n",
    "\"Let's now explore some attributes and methods of the ETdata class.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A00067', 'A00071', 'A00082', 'A00083', 'A00093']\n"
     ]
    }
   ],
   "source": [
    "# subject IDs\n",
    "subjs = sample_etdata.subjs\n",
    "print(subjs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'duration': 25.010421008753646,\n",
       " 'nframes': 600,\n",
       " 'fps': 23.99,\n",
       " 'frame_width': 720,\n",
       " 'frame_height': 480}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_etdata.stim_mediainfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/RA1005/office_sample',\n",
       " '/RA1004/office_sample',\n",
       " '/RA1003/office_sample',\n",
       " '/RA1002/office_sample',\n",
       " '/RA1001/office_sample']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_etdata.hdf_datakeys[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 117.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A00067':         RecTime       GazeX       GazeY  PupilDiameter\n",
       " 0      0.002554  412.861168  189.484155       3.287816\n",
       " 1      0.005807  412.075109  188.519504       3.290534\n",
       " 2      0.009169  412.557714  191.450572       3.292244\n",
       " 3      0.012507  413.389542  188.727479       3.287925\n",
       " 4      0.015879  413.669093  192.624907       3.304099\n",
       " ...         ...         ...         ...            ...\n",
       " 7496  24.986201  249.658202   90.128785       3.631838\n",
       " 7497  24.989552  249.601103   91.402781       3.630762\n",
       " 7498  24.992909  249.772453   88.924327       3.627809\n",
       " 7499  24.996273  249.687696   90.123242       3.621965\n",
       " 7500  24.999531  248.554462   89.683546       3.625768\n",
       " \n",
       " [7501 rows x 4 columns]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ET data from the HDF file for a sample subject                           \n",
    "sample_etdata.load_rawdata(subjs_use=subjs[0])\n",
    "\n",
    "# note that the ET data is a dictionary with\n",
    "# the key is subject ID and the value is a pandas.dataframe \n",
    "subj0_rawdata = sample_etdata.rawdata\n",
    "\n",
    "subj0_rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:00<00:00, 159.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'all_subjs_rawdata' is a <class 'dict'> with size of 153.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load ET data from the HDF file for all subjects\n",
    "sample_etdata.load_rawdata()\n",
    "\n",
    "# see raw ET data, which is a dictionary with\n",
    "# keys = subject IDs and values = pandas.dataframes \n",
    "all_subjs_rawdata = sample_etdata.rawdata\n",
    "\n",
    "print(f\"'all_subjs_rawdata' is a {type(all_subjs_rawdata)} with size of {len(all_subjs_rawdata)}.\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when dealing with a large number of participants or long-duration experiments, it may not be optimal to load all the data at once as this could consume a large amount of memory. A better approach to handling data is to use ETdata.get_timebinned_data() instead. This ETdata method loads the eye-tracking data for each subject individually and downsamples the data by averaging the gaze data points within a specific time bin duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data and applying timebins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 36.04it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading ET data using a time bin. For analyses, we usually need to time bin the data.\n",
    "# enter a time bin duration in seconds or set timebin_sec='frame_duration' [default]\n",
    "sample_etdata.get_timebinned_data(timebin_sec='frame_duration', \n",
    "                                  split_groups=True, # splits ASDs and TDs into two groups in returned data\n",
    "                                  bin_operation='mean', \n",
    "                                  fix_length=True, # use the same number of time bins across subjects\n",
    "                                  save_output=True, # save downsampled data\n",
    "                                  output_dir='sample_pkldata', # a directory to save the output file\n",
    "                                  )\n",
    "\n",
    "tbinned_data = sample_etdata.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that once ETdata.get_timebinned_data() method is run with the `save_output=True` option, the downsampled data is saved in the user-provided `output_dir`. Then, the downsampled data can be loaded directly without having to load the initial raw data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for taskname: office_sample\n"
     ]
    }
   ],
   "source": [
    "# making a new instance of the ETdata class while quickly loading the data from the saved downsampled data\n",
    "sampledata_pickle_file = './sample_pkldata/timebinned_data_office_sample_frame_duration.pkl'\n",
    "sample_etdata_re = ETdata(data_file=sampledata_pickle_file,\n",
    "                          subj_info_file=subj_info_file,\n",
    "                          use_subj_info=True, # use the group info for the subjects \n",
    "                          stim_dir=expdata_dir, # directory where the video stimulus is\n",
    "                          stimname_map=stimname_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'duration': 25.010421008753646,\n",
       " 'nframes': 600,\n",
       " 'fps': 23.99,\n",
       " 'frame_width': 720,\n",
       " 'frame_height': 480}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_etdata_re.stim_mediainfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick visualization of gaze data\n",
    "sample_etdata_re.visualize_gaze(save_viz=True,\n",
    "                                show_viz=True, # if you get an openCV related error, set this to False\n",
    "                                )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command will generate the following visualization:\n",
    "\n",
    "![gaze scatters](./gaze_visualization/office_sample_vid_ETgaze.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize two groups separately with heatmaps.\n",
    "sample_etdata_re.visualize_2groups(save_viz=True,\n",
    "                                   show_viz=True, # if you get an openCV related error, set this to False\n",
    "                                  )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command will generate the following visualization:\n",
    "\n",
    "![heatmaps viz](./gaze_visualization/office_sample_vid_compare_grps.gif)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_alabeye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
